{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from django_for_jupyter import init_django\n",
    "init_django()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    book_id                                            content\n",
      "0      3001  CDMA capacity and quality optimization code di...\n",
      "1      3002  Image databases : Search and retrieval of digi...\n",
      "2      3003  Practical handbook on image processing for sci...\n",
      "3      3004  Analytics, data science, & artificial intellig...\n",
      "4      3005  Composing cyberspace : Identity, community, an...\n",
      "..      ...                                                ...\n",
      "72     3073  Giáo trình đảm bảo chất lượng phần mềm Softwar...\n",
      "73     3074  Data engineering Fuzzy mathematics in systems ...\n",
      "74     3075  Digital image processing Image processing Digi...\n",
      "75     3076  Digital image processing using MATLAB Image pr...\n",
      "76     3095  MySQL/PHP database applications Database desig...\n",
      "\n",
      "[77 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# tạo dataframe content chứa dữ liệu cho gợi ý dựa trên thể loại\n",
    "from home.models import Book_Topic, Book\n",
    "from home.models import ContentBook\n",
    "import pandas as pd\n",
    "books = Book.objects.all().order_by('book_id')\n",
    "bookTopic = Book_Topic.objects.prefetch_related('topic_id').order_by('book_id')\n",
    "check = True\n",
    "dics = []\n",
    "for book in books:\n",
    "    content = book.book_title\n",
    "    topics = bookTopic.filter(book_id = book.book_id)\n",
    "    for topic in topics:\n",
    "        content+=' '+topic.topic_id.topic_name\n",
    "    dic = {'book_id': book.book_id,\n",
    "            'content': content\n",
    "           }\n",
    "    dics.append(dic) \n",
    "book_df = pd.DataFrame(dics)\n",
    "print(book_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    book_id                                            content\n",
      "0      3001  CDMA capacity and quality optimization code di...\n",
      "1      3002  Image databases : Search and retrieval of digi...\n",
      "2      3003  Practical handbook on image processing for sci...\n",
      "3      3004  Analytics, data science, & artificial intellig...\n",
      "4      3005  Composing cyberspace : Identity, community, an...\n",
      "..      ...                                                ...\n",
      "72     3073  Giáo trình đảm bảo chất lượng phần mềm Softwar...\n",
      "73     3074  Data engineering Fuzzy mathematics in systems ...\n",
      "74     3075  Digital image processing Image processing Digi...\n",
      "75     3076  Digital image processing using MATLAB Image pr...\n",
      "76     3095  MySQL/PHP database applications Database desig...\n",
      "\n",
      "[77 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "from home.models import ContentBook\n",
    "import pandas as pd\n",
    "bookContent = ContentBook.objects.all().order_by('book_id')\n",
    "dics = []\n",
    "for book in bookContent:\n",
    "    dic = {\n",
    "        'book_id': book.book_id,\n",
    "        'content': book.content\n",
    "    }\n",
    "    dics.append(dic)\n",
    "book_df = pd.DataFrame(dics)\n",
    "print(book_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction import text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "enlish_stop_words = text.ENGLISH_STOP_WORDS\n",
    "vietnamese_stop_words = [\"và\", \"là\", \"của\", \"những\", \"với\", \"từ\", \"một\", \"được\", \"khi\", \"đã\", \"cho\", \"vì\", \"ở\", \"này\", \"giáo\", \"trình\", \"lập\", \"trình\"]\n",
    "combine_stop_words = list(enlish_stop_words) + vietnamese_stop_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "book_tfidf = TfidfVectorizer(stop_words=combine_stop_words)\n",
    "book_df['content'] = book_df['content'].fillna('')\n",
    "book_content_matrix = book_tfidf.fit_transform(book_df['content'])\n",
    "book_content_matrix.shape\n",
    "\n",
    "cosine_similarity = linear_kernel(book_content_matrix, book_content_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Lưu TF-IDF Vectorizer\n",
    "with open('./home/recommend/book_tfidf_vectorizer.pkl', 'wb') as f:\n",
    "    pickle.dump(book_tfidf, f)\n",
    "\n",
    "with open('./home/recommend/book_cosine_similarity.pkl', 'wb') as f:\n",
    "    pickle.dump(cosine_similarity, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'content'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[128], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m bookContents \u001b[38;5;241m=\u001b[39m ContentBook\u001b[38;5;241m.\u001b[39mobjects\u001b[38;5;241m.\u001b[39mall()\u001b[38;5;241m.\u001b[39morder_by(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbook_id\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m book_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(bookContents)   \n\u001b[1;32m----> 7\u001b[0m book_content_matrix \u001b[38;5;241m=\u001b[39m book_tfidf\u001b[38;5;241m.\u001b[39mfit_transform(\u001b[43mbook_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)  \n",
      "File \u001b[1;32mc:\\Users\\thait\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:4090\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4088\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4089\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4090\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4092\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\thait\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\range.py:417\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    415\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[1;32m--> 417\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[0;32m    418\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'content'"
     ]
    }
   ],
   "source": [
    "from home.models import ContentBook\n",
    "import pickle\n",
    "with open('./home/recommend/book_tfidf_vectorizer.pkl', 'rb') as f:\n",
    "    book_tfidf = pickle.load(f)\n",
    "bookContents = ContentBook.objects.all().order_by('book_id')\n",
    "book_df = pd.DataFrame(bookContents)   \n",
    "book_content_matrix = book_tfidf.fit_transform(book_df['content'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The choice is: 3067 Giáo trình lập trình cho thiết bị di động\n",
      "3021 - iOS 9 Application Development in 24 hours \n",
      "3015 - IOS Programming the big nerd ranch guide : The Big Nerd Ranch guide \n",
      "3053 - Giáo trình lập trình hướng đối tượng Java \n",
      "3072 - Giáo trình lập trình .Net \n",
      "3063 - Giáo trình lập trình hướng đối tượng \n"
     ]
    }
   ],
   "source": [
    "# Thao tac tinh toan va dua ra goi y\n",
    "choice = 67\n",
    "similarity_scores = list(enumerate(cosine_similarity[choice-1]))\n",
    "similarity_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)\n",
    "similarity_scores = similarity_scores[1:6]\n",
    "\n",
    "# Get the similar books index\n",
    "books_index = [i[0] for i in similarity_scores]\n",
    "books = Book.objects.all().order_by('book_id')\n",
    "# printing the top 5 most similar books using integer-location based indexing (iloc)\n",
    "print(f'The choice is: {books[choice-1].book_id} {books[choice-1].book_title}')\n",
    "for i in books_index:\n",
    "    print(f'{books[i].book_id} - {books[i].book_title} ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Giả sử bạn có dữ liệu về sách mới\n",
    "new_books_df['content'] = new_books_df['content'].fillna('')\n",
    "\n",
    "# Vector hóa nội dung sách mới\n",
    "new_book_content_matrix = book_tfidf.transform(new_books_df['content'])\n",
    "\n",
    "# Cập nhật ma trận cosine similarity\n",
    "new_cosine_similarity = linear_kernel(new_book_content_matrix, book_content_matrix)\n",
    "\n",
    "# Gộp ma trận cũ và mới lại để cập nhật toàn bộ hệ thống\n",
    "cosine_similarity = linear_kernel(book_content_matrix, book_content_matrix)\n",
    "\n",
    "# Lưu lại các dữ liệu đã cập nhật\n",
    "with open('book_tfidf_vectorizer.pkl', 'wb') as f:\n",
    "    pickle.dump(book_tfidf, f)\n",
    "\n",
    "with open('book_cosine_similarity.pkl', 'wb') as f:\n",
    "    pickle.dump(cosine_similarity, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from django_for_jupyter import init_django\n",
    "init_django()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction import text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Khởi tạo lại tfids và cosine\n",
    "from home.models import ContentBook, Book, Book_Topic\n",
    "bookContents = ContentBook.objects.all().order_by('book_id').values('book_id', 'content')\n",
    "book_df = pd.DataFrame(bookContents)\n",
    "\n",
    "book_tfidf = TfidfVectorizer(stop_words=combine_stop_words)\n",
    "book_df['content'] = book_df['content'].fillna('')\n",
    "book_content_matrix = book_tfidf.fit_transform(book_df['content'])\n",
    "\n",
    "cosine_similarity = linear_kernel(book_content_matrix, book_content_matrix)\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Lưu TF-IDF Vectorizer\n",
    "with open('./home/recommend/book_tfidf_vectorizer.pkl', 'wb') as f:\n",
    "    pickle.dump(book_tfidf, f)\n",
    "\n",
    "with open('./home/recommend/book_cosine_similarity.pkl', 'wb') as f:\n",
    "    pickle.dump(cosine_similarity, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database systems the complete book Database design (Thiết kế database) Database management (Quản trị database)\n",
      "Database systems the complete book Database design (Thiết kế database) Database management (Quản trị database)\n"
     ]
    }
   ],
   "source": [
    "from home.models import ContentBook, Book, Book_Topic\n",
    "import pandas as pd\n",
    "latest_book = Book.objects.latest('book_id')\n",
    "content = latest_book.book_title\n",
    "topics = Book_Topic.objects.filter(book_id=latest_book.book_id).select_related('topic_id')\n",
    "for topic in topics:\n",
    "    content+=' '+ topic.topic_id.topic_name\n",
    "print(content)\n",
    "# newContent = ContentBook(book = latest_book, content = content)\n",
    "# newContent.save()\n",
    "newContentDic ={\n",
    "    'book_id': latest_book.book_id,\n",
    "    'content': content\n",
    "}\n",
    "newContent_df = pd.DataFrame(newContentDic, index=[0])\n",
    "print(newContent_df['content'][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from home.models import ContentBook\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "import pickle\n",
    "from scipy.sparse import vstack\n",
    "\n",
    "# open tfidf.pkl to load book_tfidf\n",
    "with open('./home/recommend/book_tfidf_vectorizer.pkl', 'rb') as f:\n",
    "    book_tfidf = pickle.load(f)\n",
    "    \n",
    "# load tạo dataframe cho ContentBook cũ  \n",
    "bookContents = ContentBook.objects.all().order_by('book_id').values('book_id', 'content')\n",
    "book_df = pd.DataFrame(bookContents)\n",
    "book_df['content'] = book_df['content'].astype(str)\n",
    "\n",
    "    \n",
    "newContent_df['content'] = newContent_df['content'].fillna('')\n",
    "newContent_df['content'] = newContent_df['content'].astype(str)\n",
    "\n",
    "# Vector hóa nội dung sách mới\n",
    "book_content_matrix = book_tfidf.fit_transform(book_df['content']) \n",
    "newContent_matrix = book_tfidf.transform(newContent_df['content'])\n",
    "\n",
    "# Gộp ma trận nội dung sách cũ và mới lại\n",
    "updatedContent_matrix = vstack([book_content_matrix, newContent_matrix])\n",
    "    \n",
    "# Cập nhật ma trận cosine similarity cho toàn bộ hệ thống\n",
    "cosine_similarity = linear_kernel(updatedContent_matrix, updatedContent_matrix)\n",
    "\n",
    "\n",
    "# Lưu TF-IDF Vectorizer\n",
    "with open('./home/recommend/book_tfidf_vectorizer.pkl', 'wb') as f:\n",
    "    pickle.dump(book_tfidf, f)\n",
    "\n",
    "with open('./home/recommend/book_cosine_similarity.pkl', 'wb') as f:\n",
    "    pickle.dump(cosine_similarity, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data structure (cấu trúc dữ liệu)\n",
      "Perl database programming Data structure (cấu trúc dữ liệu)\n",
      "Database structure\n",
      "Perl database programming Data structure (cấu trúc dữ liệu) Database structure\n",
      "   book_id                                            content\n",
      "0     3079  Perl database programming Data structure (cấu ...\n"
     ]
    }
   ],
   "source": [
    "# ham update content book khi update bôok\n",
    "# lay ra title, topics của cuốn sách mới nhất được cập nhật thông qua created_at\n",
    "# chạy lại vòng lặp topic và cập nhật content dựa vào book_id\n",
    "from home.models import ContentBook, Book, Book_Topic\n",
    "import pandas as pd\n",
    "lasted_update = Book.objects.latest('created_at')\n",
    "\n",
    "content = lasted_update.book_title\n",
    "content = str(content)\n",
    "topics = Book_Topic.objects.filter(book_id_id = lasted_update.book_id).select_related('topic_id')\n",
    "for topic in topics:\n",
    "    print(str(topic.topic_id.topic_name))\n",
    "    content+=' '+ str(topic.topic_id.topic_name)\n",
    "    print(content)\n",
    "content_update = ContentBook.objects.get(book_id = lasted_update.book_id)\n",
    "content_update.content = content\n",
    "content_update.save()\n",
    "\n",
    "updateContentDic = {\n",
    "    'book_id': lasted_update.book_id,\n",
    "    'content': content\n",
    "}\n",
    "updateContent_df = pd.DataFrame(updateContentDic, index=[0])\n",
    "print(updateContent_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
